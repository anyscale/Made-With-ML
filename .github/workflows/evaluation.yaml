name: evaluation
on:
  pull_request:
    branches:
    - main  # this workflow is triggered on PRs to the main branch

jobs:
  evaluate-model:
    runs-on: ubuntu-latest
    steps:

      # Set up AWS credentials
      - name: Set up AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: us-west-2

      # Checkout our repository
      - name: Checkout repo
        uses: actions/checkout@v3

      # Set up the appropriate Python version
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'

      # Install our Python dependencies
      - name: Install dependencies
        run: |
          python -m pip install -e ".[deploy]" --no-cache-dir
          npm install fs

      # Set all the global variables that we'll use across steps and jobs
      - name: Set global vars
        run: |
          echo ANYSCALE_HOST=https://console.anyscale-staging.com >> $GITHUB_ENV
          echo ANYSCALE_CLI_TOKEN=${{ secrets.ANYSCALE_CLI_TOKEN }} >> $GITHUB_ENV
          export PROJECT_NAME="mlops-course"
          export PROJECT_ID=$(python deploy/utils/utils.py get-project-id --project-name $PROJECT_NAME)
          echo S3_BUCKET=s3://goku-mlops >> $GITHUB_ENV
          echo UUID=$(python -c 'import uuid; print(str(uuid.uuid4())[:8])') >> $GITHUB_ENV

      # Create our cluster environment
      - name: Create cluster env
        run: |
          export CLUSTER_ENV_NAME="madewithml-cluster-env"
          echo CLUSTER_ENV_BUILD_ID=$(python deploy/utils/utils.py get-latest-cluster-env-build-id $CLUSTER_ENV_NAME) >> $GITHUB_ENV

      # Train our model (could also tune)
      - name: Train model
        run: echo "Training model"

      # Evaluate our model
      - name: Evaluate model
        run: |
          python deploy/utils/job_submit.py deploy/jobs/evaluate.yaml \
            uuid=${{ env.UUID }} \
            project_id=${{ env.PROJECT_ID }} \
            build_id=${{ env.CLUSTER_ENV_BUILD_ID }} \
            upload_path=${{ env.S3_BUCKET }}/workingdir/job \
            s3_bucket=${{ env.S3_BUCKET }} \
            experiment_name=llm
      - name: Read evaluation results from S3
        run: |
          aws s3 cp ${{ env.S3_BUCKET }}/results/${{ env.UUID }}/evaluation_results.json evaluation_results.json
      - name: Comment evaluation results to PR
        uses: actions/github-script@v6
        with:
          github-token: ${{secrets.GITHUB_TOKEN}}
          script: |
            const fs = require('fs')
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: fs.readFileSync('evaluation_results.json', 'utf8')
            })

