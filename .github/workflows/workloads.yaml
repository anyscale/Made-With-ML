name: workloads
on:
  workflow_dispatch:  # for ability to manually trigger workflow
  pull_request:
    branches:
    - main  # triggered on PRs to the main branch
permissions: write-all

jobs:
  setup:
    runs-on: ubuntu-22.04
    outputs:  # outputs (that we'll reuse in other jobs)
      CLUSTER_ENV_NAME: ${{ steps.vars.outputs.CLUSTER_ENV_NAME }}
      S3_BUCKET: ${{ steps.vars.outputs.S3_BUCKET }}
    steps:
      - name: Set global vars
        id: vars
        run: |
          echo "CLUSTER_ENV_NAME=madewithml-cluster-env" >> "$GITHUB_OUTPUT"
          echo "S3_BUCKET=s3://madewithml" >> "$GITHUB_OUTPUT"

  test-code:
    runs-on: ubuntu-22.04
    needs: setup
    steps:

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          role-session-name: s3access
          aws-region: ${{ secrets.AWS_REGION }}

      # Set up dependencies
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'
          cache: 'pip'
      - run: python -m pip install -e ".[deploy]" --no-cache-dir

      # Test code
      - name: Test code
        run: |
          export ANYSCALE_HOST=${{ secrets.ANYSCALE_HOST }}
          export ANYSCALE_CLI_TOKEN=${{ secrets.ANYSCALE_CLI_TOKEN }}
          python deploy/utils.py submit-job \
            --yaml-config-fp deploy/jobs/test_code.yaml \
            --cluster-env-name ${{ needs.setup.outputs.CLUSTER_ENV_NAME }} \
            --username ${{ github.actor }} \
            --commit-id ${{ github.event.pull_request.head.sha }}

      # Read from S3
      - name: Read results from S3
        run: |
          results_path=${{ needs.setup.outputs.S3_BUCKET }}/${{ github.actor }}/results/${{ github.event.pull_request.head.sha }}
          aws s3 cp $results_path/test_code_results.txt test_code_results.txt
      - name: Check test results
        run: |
          if grep -q "failed" test_code_results.txt; then
            echo $(tail -n 1 results/test_model_results.txt)
            exit 1
          fi


  test-data:
    runs-on: ubuntu-22.04
    needs: setup
    steps:

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          role-session-name: s3access
          aws-region: ${{ secrets.AWS_REGION }}

      # Set up dependencies
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'
          cache: 'pip'
      - run: python -m pip install -e ".[deploy]" --no-cache-dir

      # Test data
      - name: Test data
        run: |
          export ANYSCALE_HOST=${{ secrets.ANYSCALE_HOST }}
          export ANYSCALE_CLI_TOKEN=${{ secrets.ANYSCALE_CLI_TOKEN }}
          python deploy/utils.py submit-job \
            --yaml-config-fp deploy/jobs/test_data.yaml \
            --cluster-env-name ${{ needs.setup.outputs.CLUSTER_ENV_NAME }} \
            --username ${{ github.actor }} \
            --commit-id ${{ github.event.pull_request.head.sha }}

      # Read and process results
      - name: Read results from S3
        run: |
          results_path=${{ needs.setup.outputs.S3_BUCKET }}/${{ github.actor }}/results/${{ github.event.pull_request.head.sha }}
          aws s3 cp $results_path/test_data_results.txt test_data_results.txt
      - name: Check test results
        run: |
          if grep -q "failed" test_code_results.txt; then
            echo $(tail -n 1 results/test_model_results.txt)
            exit 1
          fi

  train-model:
    runs-on: ubuntu-22.04
    needs: [setup, test-code, test-data]
    outputs:
      RUN_ID: ${{ steps.get-run-id.outputs.RUN_ID }}
    steps:


      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          role-session-name: s3access
          aws-region: ${{ secrets.AWS_REGION }}

      # Set up dependencies
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'
          cache: 'pip'
      - run: python -m pip install -e ".[deploy]" --no-cache-dir

      # Train model (or tune)
      - name: Train model
        run: |
          export ANYSCALE_HOST=${{ secrets.ANYSCALE_HOST }}
          export ANYSCALE_CLI_TOKEN=${{ secrets.ANYSCALE_CLI_TOKEN }}
          python deploy/utils.py submit-job \
            --yaml-config-fp deploy/jobs/train.yaml \
            --cluster-env-name ${{ needs.setup.outputs.CLUSTER_ENV_NAME }} \
            --run-id "" \
            --username ${{ github.actor }} \
            --commit-id ${{ github.event.pull_request.head.sha }}

      # Read and process results
      - name: Read results from S3
        run: |
          results_path=${{ needs.setup.outputs.S3_BUCKET }}/${{ github.actor }}/results/${{ github.event.pull_request.head.sha }}
          aws s3 cp $results_path/training_results.json training_results.json
          python deploy/utils.py json-to-markdown --json-fp training_results.json --markdown-fp training_results.md
      - name: Comment results on PR
        uses: thollander/actions-comment-pull-request@v2
        with:
          filePath: training_results.md

      # Get run ID
      - name: Get run ID
        id: get-run-id
        run: echo "RUN_ID=$(jq -r '.run_id' training_results.json)" >> "$GITHUB_OUTPUT"

  evaluate-model:
    runs-on: ubuntu-22.04
    needs: [setup, train-model]
    steps:

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          role-session-name: s3access
          aws-region: ${{ secrets.AWS_REGION }}

      # Set up dependencies
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'
          cache: 'pip'
      - run: python -m pip install -e ".[deploy]" --no-cache-dir

      # Evaluate model
      - name: Evaluate model
        run: |
          export ANYSCALE_HOST=${{ secrets.ANYSCALE_HOST }}
          export ANYSCALE_CLI_TOKEN=${{ secrets.ANYSCALE_CLI_TOKEN }}
          python deploy/utils.py submit-job \
            --yaml-config-fp deploy/jobs/evaluate.yaml \
            --cluster-env-name ${{ needs.setup.outputs.CLUSTER_ENV_NAME }} \
            --run-id ${{ needs.train-model.outputs.RUN_ID }} \ \
            --username ${{ github.actor }} \
            --commit-id ${{ github.event.pull_request.head.sha }}

      # Read and process results
      - name: Read results from S3
        run: |
          results_path=${{ needs.setup.outputs.S3_BUCKET }}/${{ github.actor }}/results/${{ github.event.pull_request.head.sha }}
          aws s3 cp $results_path/evaluation_results.json evaluation_results.json
          python deploy/utils.py json-to-markdown --json-fp evaluation_results.json --markdown-fp evaluation_results.md
      - name: Comment results on PR
        uses: thollander/actions-comment-pull-request@v2
        with:
          filePath: evaluation_results.md

  test-model:
    runs-on: ubuntu-22.04
    needs: [setup, train-model]
    steps:

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          role-session-name: s3access
          aws-region: ${{ secrets.AWS_REGION }}

      # Set up dependencies
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'
          cache: 'pip'
      - run: python -m pip install -e ".[deploy]" --no-cache-dir

      # Test model
      - name: Test model
        run: |
          export ANYSCALE_HOST=${{ secrets.ANYSCALE_HOST }}
          export ANYSCALE_CLI_TOKEN=${{ secrets.ANYSCALE_CLI_TOKEN }}
          python deploy/utils.py submit-job \
            --yaml-config-fp deploy/jobs/test_model.yaml \
            --cluster-env-name ${{ needs.setup.outputs.CLUSTER_ENV_NAME }} \
            --run-id ${{ needs.train-model.outputs.RUN_ID }} \
            --username ${{ github.actor }} \
            --commit-id ${{ github.event.pull_request.head.sha }}

      # Read and process results
      - name: Read results from S3
        run: |
          results_path=${{ needs.setup.outputs.S3_BUCKET }}/${{ github.actor }}/results/${{ github.event.pull_request.head.sha }}
          aws s3 cp $results_path/test_model_results.txt test_model_results.txt
      - name: Check test results
        run: |
          if grep -q "failed" test_model_results.txt; then
            echo $(tail -n 1 results/test_model_results.txt)
            exit 1
          fi

  compare-to-prod:
    runs-on: ubuntu-22.04
    needs: [setup, evaluate-model, test-model]
    steps:

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          role-session-name: s3access
          aws-region: ${{ secrets.AWS_REGION }}

      # Set up dependencies
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10.11'
          cache: 'pip'
      - run: python -m pip install -e ".[deploy]" --no-cache-dir

      # Compare model to production
      - name: Compare model
        run: echo "Compare model"
